{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c615b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/24 19:41:39 WARN Utils: Your hostname, DESKTOP-3ADPNV0 resolves to a loopback address: 127.0.1.1; using 172.25.24.22 instead (on interface eth0)\n",
      "22/08/24 19:41:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/24 19:41:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# Cell to create a spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 ASSIGNMENT 1 DUSTIN\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bea7237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "yellow = spark.read.parquet('../../mast30034-project-1-dustintano10/data/raw/yellow_taxi/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8eb09ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54251562"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows before preprocessing\n",
    "\n",
    "yellow.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac50f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column called day_of_week to get day of week for the trip and is_weekend which identify if record is a \n",
    "# weekend or not\n",
    "# drop day_of_week since we only want to know if its weekend or not\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "yellow = yellow.withColumn(\"day_of_week\", date_format(col(\"tpep_pickup_datetime\"),\"E\"))\n",
    "\n",
    "yellow = yellow.withColumn(\"is_weekend\", col(\"day_of_week\").isin([\"Sat\", \"Sun\"]).cast(\"boolean\"))\n",
    "\n",
    "yellow = yellow.drop(\"day_of_week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a381f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separates the date and time from both the pickup and dropoff date time columns\n",
    "# creates new columns for pickup/dropoff date\n",
    "\n",
    "yellow = yellow.withColumn(\"pickup_date\",\n",
    "                 to_date(col(\"tpep_pickup_datetime\"),\"yyyy-MM-dd\"))\n",
    "\n",
    "yellow = yellow.withColumn(\"dropoff_date\",\n",
    "                 to_date(col(\"tpep_dropoff_datetime\"),\"yyyy-MM-dd\"))\n",
    "\n",
    "# ensure passenger_count is not 0\n",
    "yellow = yellow.where( (F.col('passenger_count') > 0) )\n",
    "\n",
    "#drop columns that are not important for analysis\n",
    "yellow = yellow.drop(\"extra\", \"mta_tax\", \"congestion_surcharge\", \"airport_fee\", \"improvement_surcharge\",\n",
    "                    \"passenger_count\", \"store_and_fwd_flag\", )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "368ad2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out all other payment_types as tips are only counted with credit card payment\n",
    "yellow_credit = yellow.filter(F.col('payment_type') == 1)\n",
    "\n",
    "# remove records that has trips starting before the month of october\n",
    "yellow_credit = yellow_credit.filter(F.col('pickup_date') >= '2018-10-01')\n",
    "\n",
    "# remove other RatecodeID's as they make up such a small amount of the total dataset\n",
    "yellow_credit = yellow_credit.where( (F.col('RatecodeID') == 1) | (F.col('RatecodeID') == 2))\n",
    "\n",
    "# remove VendorID not being 1 or 2\n",
    "yellow_credit = yellow_credit.where( (F.col('VendorID') > 0 ) & (F.col('VendorID') < 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "656a1117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove records which don't follow the initial amount of 2.5 from fare_amount\n",
    "\n",
    "yellow_credit = yellow_credit.where(F.col('fare_amount') >= 2.5)\n",
    "\n",
    "# remove records where trip distance is 0\n",
    "\n",
    "yellow_credit = yellow_credit.where(F.col('trip_distance') > 0)\n",
    "\n",
    "# remove records where the PU and DO location is not in the range\n",
    "\n",
    "yellow_credit = yellow_credit.where( ( F.col('PULocationID') < 264 ) & (F.col('DOLocationID') < 264) & \n",
    "                                    ( F.col('PULocationID') > 0) & (F.col('DOLocationID') > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16af47ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a length of trip column in mins\n",
    "\n",
    "yellow_credit = yellow_credit.withColumn('trip_length', \n",
    "                         round((unix_timestamp('tpep_dropoff_datetime') - unix_timestamp('tpep_pickup_datetime'))/60, 4))\n",
    "\n",
    "# filters out trips that are negative and less than 2 minutes in time length\n",
    "yellow_credit = yellow_credit.where( (F.col('trip_length') > 2 ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b11a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed outliers for fare_amount\n",
    "\n",
    "yellow_credit.select( percentile_approx(\"fare_amount\", [0.25, 0.75], 10000).alias(\"quantiles_fare\") )\n",
    "\n",
    "\n",
    "upper_q_fare = 13.0\n",
    "lower_q_fare = 6.5\n",
    "\n",
    "IQ_fare = upper_q_fare-lower_q_fare\n",
    "\n",
    "borderline_upper_fare = upper_q_fare + (1.5 * IQ_fare)\n",
    "borderline_lower_fare = lower_q_fare - (1.5 * IQ_fare)\n",
    "\n",
    "yellow_credit = yellow_credit.where( (F.col('fare_amount') <= borderline_upper_fare ) & \n",
    "                                      (F.col('fare_amount') >= borderline_lower_fare) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f294a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we load the curated nba_attendance and convert the Date column into date type\n",
    "# Then we convert the whole pandas dataframe into a spark dataframe \n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "nba_attendance = pd.read_csv('../../mast30034-project-1-dustintano10/data/curated/nba_attendance_new.csv')\n",
    "\n",
    "nba_attendance['Date'] = pd.to_datetime(nba_attendance['Date'], format='%Y%m%d')\n",
    "\n",
    "schema = StructType([\n",
    "StructField(\"Date\", DateType(), True),\n",
    "StructField(\"Start(ET)\", StringType(), True),\n",
    "StructField(\"Attendance\", IntegerType(), True),\n",
    "StructField(\"Win\", StringType(), True),\n",
    "StructField(\"margin_victory/loss\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "nba_attendance_spark = spark.createDataFrame(nba_attendance, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c89a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joins the nba attendance with the yellow_credit dataframe\n",
    "yellow_credit = yellow_credit.join(nba_attendance_spark, yellow_credit.pickup_date == nba_attendance_spark.Date, 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adf83760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters the data to only be records where the knicks are playing\n",
    "yellow_credit = yellow_credit.filter( F.col('Date').isNotNull() )\n",
    "\n",
    "# filter records where pickup_date and dropoff_date is not the same as we are focusing just on days the knicks are playing\n",
    "# they also only make a small percentage of the data\n",
    "\n",
    "yellow_credit = yellow_credit.where((F.col(\"pickup_date\") == F.col(\"dropoff_date\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9118f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the Date column as it is a duplicate\n",
    "yellow_credit = yellow_credit.drop(\"VendorID\", \"payment_type\", \"RatecodeID\", \"pickup_date\", \"dropoff_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2dd93be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6165834"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows after preprocessing\n",
    "yellow_credit.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "290fa244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# saves the new yellow_credit dataframe\n",
    "yellow_credit.write.mode('overwrite').parquet('../../mast30034-project-1-dustintano10/data/curated/yellow/yellow_credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1f788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

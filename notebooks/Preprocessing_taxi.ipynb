{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c615b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/15 15:29:05 WARN Utils: Your hostname, DESKTOP-3ADPNV0 resolves to a loopback address: 127.0.1.1; using 192.168.154.134 instead (on interface eth0)\n",
      "22/08/15 15:29:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/15 15:29:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# Cell to create a spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 ASSIGNMENT 1 DUSTIN\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bea7237",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow = spark.read.parquet('../../mast30034-project-1-dustintano10/data/raw/yellow_taxi/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb09ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " VendorID              | 1                   \n",
      " tpep_pickup_datetime  | 2018-10-01 00:23:34 \n",
      " tpep_dropoff_datetime | 2018-10-01 00:44:50 \n",
      " passenger_count       | 1.0                 \n",
      " trip_distance         | 6.2                 \n",
      " RatecodeID            | 1.0                 \n",
      " store_and_fwd_flag    | N                   \n",
      " PULocationID          | 68                  \n",
      " DOLocationID          | 7                   \n",
      " payment_type          | 2                   \n",
      " fare_amount           | 20.5                \n",
      " extra                 | 0.5                 \n",
      " mta_tax               | 0.5                 \n",
      " tip_amount            | 0.0                 \n",
      " tolls_amount          | 0.0                 \n",
      " improvement_surcharge | 0.3                 \n",
      " total_amount          | 21.8                \n",
      " congestion_surcharge  | null                \n",
      " airport_fee           | null                \n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: integer (nullable = true)\n",
      " |-- airport_fee: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "yellow.show(1, vertical=True, truncate=100)\n",
    "yellow.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac50f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column called day_of_week to get day of week for the trip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a381f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separates the date and time from both the pickup and dropoff date time columns\n",
    "# creates new columns for pickup/dropoff date and pickup/dropoff time\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "yellow = yellow.withColumn(\"pickup_date\",\n",
    "                 to_date(col(\"tpep_pickup_datetime\"),\"yyyy-MM-dd\"))\n",
    "\n",
    "yellow = yellow.withColumn(\"dropoff_date\",\n",
    "                 to_date(col(\"tpep_dropoff_datetime\"),\"yyyy-MM-dd\"))\n",
    "\n",
    "yellow = yellow.withColumn(\"pickup_time\", date_format('tpep_pickup_datetime', 'HH:mm:ss'))\n",
    "\n",
    "yellow = yellow.withColumn(\"dropoff_time\", date_format('tpep_dropoff_datetime', 'HH:mm:ss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368ad2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns I deemed irrelevant\n",
    "# For congestions_surcharge,airport_fee,VendorID and passenger_count I see them as irrelevant due to the fact \n",
    "# they don't really contribute to what I am focusing in which is the taxi profits, tipping and location popularity\n",
    "# For tpep_pickup_datetime and tpep_dropoff_datetime, I created new columns for them.\n",
    "\n",
    "yellow = yellow.drop('congestion_surcharge','airport_fee','tpep_pickup_datetime','tpep_dropoff_datetime','VendorID'\n",
    "                     ,'passenger_count', 'store_and_fwd_flag')\n",
    "\n",
    "yellow_credit = yellow.filter(F.col('payment_type') == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d6169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove records that has trips starting before the month of october\n",
    "yellow_credit = yellow_credit.filter(F.col('pickup_date') >= '2018-10-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f294a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we load the curated nba_attendance and convert the Date column into date type\n",
    "# Then we convert the whole pandas dataframe into a spark dataframe \n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "nba_attendance = pd.read_csv('../../mast30034-project-1-dustintano10/data/curated/nba_attendance_new.csv')\n",
    "\n",
    "nba_attendance['Date'] = pd.to_datetime(nba_attendance['Date'], format='%Y%m%d')\n",
    "\n",
    "schema = StructType([\n",
    "StructField(\"Date\", DateType(), True),\n",
    "StructField(\"Start(ET)\", StringType(), True),\n",
    "StructField(\"Attend.\", StringType(), True),\n",
    "StructField(\"Arena\", StringType(), True),\n",
    "StructField(\"Day_of_week\", StringType(), True)\n",
    "])\n",
    "\n",
    "nba_attendance_spark = spark.createDataFrame(nba_attendance, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c89a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joins the nba attendance with the yellow_credit dataframe\n",
    "yellow_credit = yellow_credit.join(nba_attendance_spark, yellow_credit.pickup_date == nba_attendance_spark.Date, 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290fa244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves the new yellow_credit dataframe\n",
    "yellow_credit.write.mode('overwrite').parquet('../../mast30034-project-1-dustintano10/data/curated/yellow/yellow_credit')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
